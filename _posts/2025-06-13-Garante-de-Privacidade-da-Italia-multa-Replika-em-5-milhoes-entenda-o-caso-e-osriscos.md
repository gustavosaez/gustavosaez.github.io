---
layout: post
title: "Garante de Privacidade da Itália multa Replika em €5 milhões: entenda o caso e os riscos!" #titulo para a barra de enderecos
date: 2025-06-13 09:41 -0300 #formato padrão data e hora
categories: Post
path: "_posts" #caminho da pasta
tags: [ "privacidade", "seguranca", "ia"  ]
#image: /images/tiktok.png
---

# Garante de Privacidade da Itália multa Replika em €5 milhões: entenda o caso e os riscos!

O *Garante per la Protezione dei Dati Personali* (Autoridade Italiana de Proteção de Dados) aplicou uma multa de 5 milhões de euros à empresa norte-americana Luka Inc., responsável pelo chatbot de inteligência artificial “Replika”. Além da penalidade, foi aberta uma nova investigação sobre como os dados pessoais são tratados durante o desenvolvimento e funcionamento do serviço.

![](/images/chatbot.png)
*Imagem gerada por IA*

### **O que é o Replika?**
- Chatbot com interface escrita e por voz.
- Permite criar um “amigo virtual” que pode ser confidente, terapeuta, parceiro romântico ou mentor.
- Popular entre jovens e adultos, especialmente pessoas emocionalmente vulneráveis.

### **Principais Motivos da Multa**

- **Falta de base legal para o tratamento de dados:** Em fevereiro de 2023, quando o app foi bloqueado na Itália, a Luka Inc. não havia definido bases jurídicas claras para o processamento dos dados dos usuários.
- **Política de privacidade inadequada:** O documento fornecido aos usuários era insuficiente em vários aspectos, deixando dúvidas sobre como os dados eram usados e protegidos.
- **Ausência de verificação de idade:** Apesar de afirmar que menores de idade não poderiam usar o serviço, não havia mecanismos eficazes para impedir o acesso de crianças e adolescentes, nem no cadastro, nem durante o uso. O sistema de verificação atual ainda é considerado falho pelo Garante.

---

### **O que o Garante exige agora?**

- Que a Luka Inc. adeque o tratamento de dados às normas do Regulamento Geral de Proteção de Dados (GDPR).
- Esclarecimentos sobre:
  - Como os dados são tratados em todas as fases do ciclo de vida do sistema de IA.
  - Avaliações de risco e medidas de proteção de dados durante o desenvolvimento e treinamento do modelo.
  - Tipos e categorias de dados utilizados.
  - Uso de técnicas de anonimização ou pseudonimização para proteger a privacidade dos usuários.

### **Por que isso importa para você?**

- Chatbots como o Replika lidam com informações sensíveis, muitas vezes confidenciais ou emocionais.
- Falhas em políticas de privacidade e ausência de controles de idade expõem principalmente jovens e pessoas vulneráveis a riscos como manipulação, exposição indevida de dados e possíveis danos psicológicos.
- O caso serve de alerta para usuários e empresas sobre a importância de exigir transparência e segurança no uso de IA e aplicativos que coletam dados pessoais.

### **Exemplo prático**

Imagine um adolescente usando o Replika para desabafar sobre problemas pessoais. Sem verificação de idade, sem garantias de anonimato e com políticas pouco claras, essas informações podem ser usadas de formas não autorizadas, expondo o jovem a riscos sérios.



### **Fique atento!**
Sempre leia as políticas de privacidade dos aplicativos, questione sobre o uso dos seus dados e, no caso de menores, supervisione o acesso a plataformas de IA e chatbots.

---
Fonte: [Garante Privacy](https://www.garanteprivacy.it/home/docweb/-/docweb-display/docweb/10132048)